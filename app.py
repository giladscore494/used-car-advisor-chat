import os
import re
import requests
import streamlit as st
from openai import OpenAI

# =============================
# ×©×œ×™×¤×ª ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not OPENAI_API_KEY or not PERPLEXITY_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘×¡×™×§×¨×˜×¡.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×¤×•× ×§×¦×™×™×ª ×§×¨×™××” ×‘×˜×•×—×” ×œÖ¾Perplexity
# =============================
def safe_perplexity_call(payload):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {"Authorization": f"Bearer {PERPLEXITY_API_KEY}", "Content-Type": "application/json"}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        data = r.json()
        if "choices" not in data:
            return f"×©×’×™××ª API: {data}"
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

# =============================
# ×©××œ×•×Ÿ â€“ 40 ×©××œ×•×ª (×¨×§ ×“×•×’×××•×ª ×›××Ÿ)
# =============================
questions = [
    "××” ×˜×•×•×— ×”×ª×§×¦×™×‘ ×©×œ×š ×œ×¨×›×‘?",
    "××” ×”×ª×§×¦×™×‘ ×”××™× ×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?",
    "××” ×”×ª×§×¦×™×‘ ×”××§×¡×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?",
    "×›××” ×§×™×œ×•××˜×¨×™× ××ª×” × ×•×¡×¢ ×‘×××•×¦×¢ ×‘×—×•×“×©?",
    "×”×× ×”×¨×›×‘ ××™×•×¢×“ ×‘×¢×™×§×¨ ×œ× ×¡×™×¢×•×ª ×¢×™×¨×•× ×™×•×ª ××• ×‘×™×Ÿ-×¢×™×¨×•× ×™×•×ª?",
    "×›××” ×× ×©×™× ×™×•×©×‘×™× ×‘×“×¨×š ×›×œ×œ ×‘×¨×›×‘?",
    "×”×× ××ª×” ×–×§×•×§ ×œ×ª× ××˜×¢×Ÿ ×’×“×•×œ?",
    "××ª×” ××ª×›× ×Ÿ ×œ× ×¡×•×¢ ×”×¨×‘×” ×¢× ×¦×™×•×“ ×›×‘×“ ××• ×’×¨×™×¨×”?",
    "××ª×” ××¢×“×™×£ ×¨×›×‘ ×‘× ×–×™×Ÿ, ×“×™×–×œ, ×”×™×‘×¨×™×“×™ ××• ×—×©××œ×™?",
    "×”×× ×—×¡×›×•×Ÿ ×‘×“×œ×§ ×§×¨×™×˜×™ ×¢×‘×•×¨×š?",
    # ... (×©××¨ ×”Ö¾40 ×©××œ×•×ª ×›××• ×§×•×“×)
]

# =============================
# ×¤×•× ×§×¦×™×•×ª Pipeline
# =============================

def analyze_needs_with_gpt(answers):
    """×©×œ×‘ 1 â€“ GPT: ×¨×©×™××ª ×“×’××™× ×¨××©×•× ×™×ª (××•×ª×××™× ×œ×™×©×¨××œ + ×ª×§×¦×™×‘)"""
    min_budget = answers.get("××” ×”×ª×§×¦×™×‘ ×”××™× ×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?", "")
    max_budget = answers.get("××” ×”×ª×§×¦×™×‘ ×”××§×¡×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?", "")

    prompt = f"""
    ××œ×• ×”×ª×©×•×‘×•×ª ××”××©×ª××©:
    {answers}

    ×”×—×–×¨ ×¨×©×™××” ×©×œ 5â€“7 ×“×’××™ ×¨×›×‘×™× ××ª××™××™×.
    ×—×©×•×‘:
    - ×”×¦×¢ ×¨×§ ×¨×›×‘×™× ×©× ××›×¨×™× ×‘×™×©×¨××œ ×‘×¤×•×¢×œ (×™×“ ×©× ×™×™×”).
    - ×›×œ×•×œ ×¨×§ ×¨×›×‘×™× ×©×”××—×™×¨×•×Ÿ ×©×œ×”× ×‘×™×“ ×©× ×™×™×” × ××¦× ×‘×˜×•×•×— {min_budget} ×¢×“ {max_budget} ×©×§×œ×™×.
    - ×”×—×–×¨ ×¨×©×™××” × ×§×™×™×”: ×¨×§ ×©× ×”×“×’×, ×›×œ ×“×’× ×‘×©×•×¨×” × ×¤×¨×“×ª, ×‘×œ×™ ××¡×¤×¨×™× ×•×‘×œ×™ ×”×¡×‘×¨×™×.
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    text = response.choices[0].message.content
    clean_models = []
    for line in text.split("\n"):
        line = line.strip()
        if not line:
            continue
        line = re.sub(r"^[0-9\.\-\â€¢\*\s]+", "", line)
        if len(line.split()) <= 6:
            clean_models.append(line)
    return clean_models

def extract_numbers_from_text(text):
    """××—×œ×¥ ××¡×¤×¨×™× ××”×˜×§×¡×˜"""
    numbers = re.findall(r'\d{1,3}(?:[ ,]\d{3})*|\d+', text)
    clean_numbers = []
    for n in numbers:
        try:
            clean_numbers.append(int(n.replace(",", "").replace(" ", "")))
        except:
            pass
    return clean_numbers

def filter_models_for_israel(models, min_budget, max_budget):
    """×©×œ×‘ 2 â€“ ×¡×™× ×•×Ÿ ×œ×¤×™ ×–××™× ×•×ª ×‘×™×©×¨××œ + ××—×™×¨×•×Ÿ ×××™×ª×™ ××•×œ ×”×ª×§×¦×™×‘"""
    filtered, debug_info = [], {}
    for model_name in models:
        payload = {
            "model": "sonar-medium-chat",
            "messages": [
                {"role": "system", "content": "×¢× ×” ×‘×§×¦×¨×”, ×œ××©×œ: '× ×¤×•×¥ ×‘×™×©×¨××œ, ××—×™×¨×•×Ÿ 12-18 ××œ×£ â‚ª' ××• '×œ× × ×¤×•×¥ ×‘×™×©×¨××œ'."},
                {"role": "user", "content": f"×”×× {model_name} × ××›×¨ ×‘×™×©×¨××œ, ×•××” ×˜×•×•×— ×”××—×™×¨×™× ×”×××™×ª×™ ×©×œ×• ×‘×™×“ ×©× ×™×™×”?"}
            ]
        }
        answer = safe_perplexity_call(payload)
        debug_info[model_name] = answer

        if isinstance(answer, str):
            ans = answer.lower()
            if "×œ× × ×¤×•×¥" in ans or "×œ× × ××›×¨" in ans:
                continue

            # ×—×™×œ×•×¥ ×˜×•×•×— ××—×™×¨ ×•×”×©×•×•××” ×œ×ª×§×¦×™×‘
            nums = extract_numbers_from_text(answer)
            if len(nums) >= 2:
                low, high = min(nums), max(nums)
                if low <= max_budget and high >= min_budget:
                    filtered.append(model_name)
            else:
                # ×× ×œ× ××¦× ××¡×¤×¨×™× ××‘×œ ×›×Ÿ ×›×ª×•×‘ × ×¤×•×¥ â†’ × ××©×¨ ×’××™×©
                if "× ×¤×•×¥" in ans or "× ××›×¨" in ans:
                    filtered.append(model_name)

    return filtered, debug_info

def fetch_models_data_with_perplexity(models, answers):
    """×©×œ×‘ 2 â€“ Perplexity: × ×ª×•× ×™× ××œ××™× (10 ×¤×¨××˜×¨×™×)"""
    all_data = {}
    for model_name in models:
        payload = {
            "model": "sonar-medium-chat",
            "messages": [
                {"role": "system", "content": "×”×—×–×¨ ××™×“×¢ ×¢×•×‘×“×ª×™ ×•×ª××¦×™×ª×™ ×‘×œ×‘×“, ×‘×¢×‘×¨×™×ª."},
                {"role": "user", "content": f"""
                ×ª×©×•×‘×•×ª ×”××©×ª××©: {answers}

                ×”×‘× ××™×“×¢ ×¢×“×›× ×™ ×¢×œ {model_name} ×‘×™×©×¨××œ, ×œ×¤×™:
                1. ×˜×•×•×— ××—×™×¨×•×Ÿ ×××•×¦×¢ ×‘×™×“ ×©× ×™×™×” (××¡×¤×¨×™×!)
                2. ×–××™× ×•×ª ×•× ×¤×•×¦×•×ª ×‘×™×©×¨××œ
                3. ×¢×œ×•×ª ×‘×™×˜×•×— ×××•×¦×¢×ª
                4. ××’×¨×ª ×¨×™×©×•×™/×˜×¡×˜ ×©× ×ª×™×ª
                5. ×ª×—×–×•×§×” ×©× ×ª×™×ª ×××•×¦×¢×ª
                6. ×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×™×“×•×¢×•×ª
                7. ×¦×¨×™×›×ª ×“×œ×§ ×××™×ª×™×ª
                8. ×™×¨×™×“×ª ×¢×¨×š ×××•×¦×¢×ª
                9. ×“×™×¨×•×’ ×‘×˜×™×—×•×ª
                10. ×–××™× ×•×ª ×—×œ×¤×™× ×‘×™×©×¨××œ

                ×”×—×–×¨ ×ª×©×•×‘×” ×›×¨×©×™××” ×××•×¡×¤×¨×ª 1â€“10 ×‘×œ×‘×“.
                """}
            ]
        }
        answer = safe_perplexity_call(payload)
        all_data[model_name] = answer
    return all_data

def final_recommendation_with_gpt(answers, models, models_data):
    """×©×œ×‘ 3 â€“ GPT: ×”××œ×¦×” ×¡×•×¤×™×ª"""
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ:
    {models}

    × ×ª×•× ×™ Perplexity:
    {models_data}

    ×¦×•×¨ ×”××œ×¦×” ×¡×•×¤×™×ª ×‘×¢×‘×¨×™×ª:
    - ×”×¦×’ ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ×”×•×¡×£ × ×™××•×§ ××™×©×™ ×œ×›×œ ×“×’×
    - ×”×©×•×•×” ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - ×›×œ×•×œ ×©×™×§×•×œ×™× ×›×œ×›×œ×™×™× (××—×™×¨×•×Ÿ, ×‘×™×˜×•×—, ×ª×—×–×•×§×”) ×•×©×™××•×©×™×™× (×‘×˜×™×—×•×ª, × ×•×—×•×ª, ×××™× ×•×ª)
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.5,
    )
    return response.choices[0].message.content

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

with st.form("car_form"):
    st.write("×¢× ×” ×¢×œ ×”×©××œ×•×Ÿ:")
    answers = {}
    for q in questions:
        answers[q] = st.text_input(q, "")
    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    with st.spinner("ğŸ¤– GPT ×‘×•×—×¨ ×“×’××™× ×¨××©×•× ×™×™×..."):
        initial_models = analyze_needs_with_gpt(answers)
    st.info(f"ğŸ“‹ ×“×’××™× ×¨××©×•× ×™×™×: {initial_models}")

    # ×ª×§×¦×™×‘ ××”×©××œ×•×Ÿ
    try:
        min_budget = int(answers.get("××” ×”×ª×§×¦×™×‘ ×”××™× ×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?", "0").replace("××œ×£","000").replace(" ",""))
    except:
        min_budget = 0
    try:
        max_budget = int(answers.get("××” ×”×ª×§×¦×™×‘ ×”××§×¡×™××œ×™ ×©×œ×š ×‘×©×§×œ×™×?", "999999").replace("××œ×£","000").replace(" ",""))
    except:
        max_budget = 999999

    with st.spinner("ğŸ‡®ğŸ‡± ××¡× ×Ÿ ×“×’××™× ××•×œ ××—×™×¨×•×Ÿ ×”×××™×ª×™..."):
        israeli_models, debug_info = filter_models_for_israel(initial_models, min_budget, max_budget)

    with st.expander("ğŸ” ×ª×©×•×‘×•×ª Perplexity ×œ×¡×™× ×•×Ÿ"):
        st.write(debug_info)

    if not israeli_models:
        st.error("âŒ ×œ× × ××¦××• ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ ×‘×˜×•×•×— ×”××—×™×¨×™× ×©×¦×™×™× ×ª.")
    else:
        st.success(f"âœ… ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ ×‘×ª×§×¦×™×‘: {israeli_models}")

        with st.spinner("ğŸŒ ×©×•×œ×£ × ×ª×•× ×™× ××œ××™× ×Ö¾Perplexity..."):
            models_data = fetch_models_data_with_perplexity(israeli_models, answers)

        with st.expander("ğŸ“Š × ×ª×•× ×™ Perplexity ×’×•×œ××™×™×"):
            st.write(models_data)

        with st.spinner("âš¡ ×™×•×¦×¨ ×”××œ×¦×” ×¡×•×¤×™×ª ×¢× GPT..."):
            summary = final_recommendation_with_gpt(answers, israeli_models, models_data)

        st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
        st.write(summary)
