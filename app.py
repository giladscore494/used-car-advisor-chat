import os
import re
import requests
import streamlit as st
from openai import OpenAI

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not OPENAI_API_KEY or not PERPLEXITY_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Perplexity
# =============================
def safe_perplexity_call(payload):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {"Authorization": f"Bearer {PERPLEXITY_API_KEY}", "Content-Type": "application/json"}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        data = r.json()
        if "choices" not in data:
            return f"×©×’×™××ª API: {data}"
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

def extract_numbers_from_text(text):
    numbers = re.findall(r'\d{1,3}(?:[ ,]\d{3})*|\d+', text)
    clean = []
    for n in numbers:
        try:
            clean.append(int(n.replace(",", "").replace(" ", "")))
        except:
            pass
    return clean

# =============================
# ×©×œ×‘ 1 â€“ GPT ××¦×™×¢ ×“×’××™× ×¨××©×•× ×™×™×
# =============================
def analyze_needs_with_gpt(answers):
    min_budget = answers["budget_min"]
    max_budget = answers["budget_max"]
    engine = answers["engine"]

    prompt = f"""
    ×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª:
    {answers}

    ×”×—×–×¨ ×¨×©×™××” ×©×œ 5â€“7 ×“×’××™ ×¨×›×‘×™× ××ª××™××™×.
    ×“×¨×™×©×•×ª ×—×•×‘×”:
    - ×¨×§ ×“×’××™× ×©× ××›×¨×™× ×‘×™×©×¨××œ ×‘×™×“ ×©× ×™×™×”.
    - ×¨×§ ×¨×›×‘×™× ×©×”××—×™×¨×•×Ÿ ×©×œ×”× ×‘×™×“ ×©× ×™×™×” × ××¦× ×‘×˜×•×•×— {min_budget}â€“{max_budget} â‚ª.
    - ×¨×§ ×¨×›×‘×™× ×¢× ×× ×•×¢ {engine}, ×× ×§×™×™× ×‘×™×©×¨××œ.
    ×”×—×–×¨ ×¨×©×™××” × ×§×™×™×”: ×›×œ ×©×•×¨×” ×©× ×“×’× ×‘×œ×‘×“, ×‘×œ×™ ××¡×¤×¨×™× ×•×‘×œ×™ ×”×¡×‘×¨×™×.
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    text = response.choices[0].message.content
    clean_models = []
    for line in text.split("\n"):
        line = line.strip()
        if line:
            line = re.sub(r"^[0-9\.\-\â€¢\*\s]+", "", line)
            if len(line.split()) <= 6:
                clean_models.append(line)
    return clean_models

# =============================
# ×©×œ×‘ 2 â€“ ×¡×™× ×•×Ÿ ×¢× Perplexity
# =============================
def filter_models_for_israel(models, min_budget, max_budget, engine):
    filtered, debug_info = [], {}
    for model_name in models:
        payload = {
            "model": "sonar",
            "messages": [
                {"role": "system", "content": "×¢× ×” ×‘×§×¦×¨×”, ×œ××©×œ: '× ×¤×•×¥ ×‘×™×©×¨××œ, ××—×™×¨×•×Ÿ 12-18 ××œ×£ â‚ª, ×× ×•×¢ ×“×™×–×œ'."},
                {"role": "user", "content": f"×”×× {model_name} × ××›×¨ ×‘×™×©×¨××œ ×‘×™×“ ×©× ×™×™×” ×¢× ×× ×•×¢ {engine}? ×•××” ×˜×•×•×— ×”××—×™×¨×™× ×”×××™×ª×™ ×©×œ×•?"}
            ]
        }
        answer = safe_perplexity_call(payload)
        debug_info[model_name] = answer

        if isinstance(answer, str):
            ans = answer.lower()
            if "×œ× × ×¤×•×¥" in ans or "×œ× × ××›×¨" in ans:
                continue

            nums = extract_numbers_from_text(answer)
            if len(nums) >= 2:
                low, high = min(nums), max(nums)
                if low <= max_budget and high >= min_budget:
                    filtered.append(model_name)
            else:
                if "× ×¤×•×¥" in ans or "× ××›×¨" in ans:
                    filtered.append(model_name)

    return filtered, debug_info

# =============================
# ×©×œ×‘ 3 â€“ × ×ª×•× ×™× ××œ××™× ×-Perplexity
# =============================
def fetch_models_data_with_perplexity(models, answers):
    all_data = {}
    engine = answers["engine"]
    for model_name in models:
        payload = {
            "model": "sonar-pro",
            "messages": [
                {"role": "system", "content": "×”×—×–×¨ ××™×“×¢ ×¢×•×‘×“×ª×™ ×•×ª××¦×™×ª×™ ×‘×œ×‘×“, ×‘×¢×‘×¨×™×ª."},
                {"role": "user", "content": f"""
                ×”×‘× ××™×“×¢ ×¢×“×›× ×™ ×¢×œ {model_name} ×‘×™×©×¨××œ ×¢× ×× ×•×¢ {engine}, ×œ×¤×™:
                1. ×˜×•×•×— ××—×™×¨×•×Ÿ ×××•×¦×¢ ×‘×™×“ ×©× ×™×™×” (××¡×¤×¨×™×!)
                2. ×–××™× ×•×ª ×•× ×¤×•×¦×•×ª ×‘×™×©×¨××œ
                3. ×¢×œ×•×ª ×‘×™×˜×•×— ×××•×¦×¢×ª
                4. ××’×¨×ª ×¨×™×©×•×™/×˜×¡×˜ ×©× ×ª×™×ª
                5. ×ª×—×–×•×§×” ×©× ×ª×™×ª ×××•×¦×¢×ª
                6. ×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×™×“×•×¢×•×ª
                7. ×¦×¨×™×›×ª ×“×œ×§ ×××™×ª×™×ª
                8. ×™×¨×™×“×ª ×¢×¨×š ×××•×¦×¢×ª
                9. ×“×™×¨×•×’ ×‘×˜×™×—×•×ª
                10. ×–××™× ×•×ª ×—×œ×¤×™× ×‘×™×©×¨××œ
                """}
            ]
        }
        answer = safe_perplexity_call(payload)
        all_data[model_name] = answer
    return all_data

# =============================
# ×©×œ×‘ 4 â€“ GPT ××¡×›× ×”××œ×¦×”
# =============================
def final_recommendation_with_gpt(answers, models, models_data):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ:
    {models}

    × ×ª×•× ×™ Perplexity:
    {models_data}

    ×¦×•×¨ ×”××œ×¦×” ×¡×•×¤×™×ª ×‘×¢×‘×¨×™×ª:
    - ×”×¦×’ ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ×¤×¨×˜ ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - ×›×œ×•×œ × ×™××•×§×™× ××™×©×™×™× ×œ×¤×™ ×”×ª×§×¦×™×‘, ×¡×•×’ ×”×× ×•×¢ ×•×”×©×™××•×©×™×
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.5,
    )
    return response.choices[0].message.content

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

with st.form("car_form"):
    st.write("×¢× ×” ×¢×œ ×”×©××œ×•×Ÿ:")

    answers = {}
    answers["budget_range"] = st.selectbox("××” ×˜×•×•×— ×”×ª×§×¦×™×‘ ×©×œ×š ×œ×¨×›×‘?", ["5â€“10K", "10â€“20K", "20â€“40K", "40K+"])
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "10000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "20000"))
    answers["km"] = st.selectbox("×›××” ×§×™×œ×•××˜×¨×™× ××ª×” × ×•×¡×¢ ×‘×—×•×“×©?", ["<1000", "1000â€“2000", "2000â€“4000", "4000+"])
    answers["engine"] = st.radio("××™×–×” ×¡×•×’ ×× ×•×¢ ××ª×” ××¢×“×™×£?", ["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×—×©××œ×™"])
    answers["usage"] = st.radio("××” ×”×©×™××•×© ×”×¢×™×§×¨×™ ×‘×¨×›×‘?", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])
    answers["size"] = st.selectbox("××™×–×” ×’×•×“×œ ×¨×›×‘ ××ª××™× ×œ×š?", ["×§×˜×Ÿ", "××©×¤×—×ª×™", "SUV", "×˜× ×“×¨"])
    answers["passengers"] = st.radio("×›××” ×× ×©×™× × ×•×¡×¢×™× ×œ×¨×•×‘ ×‘×¨×›×‘?", ["1", "2â€“3", "4â€“5", "6+"])
    answers["fuel_eff"] = st.radio("×¢×“ ×›××” ×—×©×•×‘ ×—×¡×›×•×Ÿ ×‘×“×œ×§?", ["×œ× ×—×©×•×‘", "×‘×™× ×•× ×™", "×—×©×•×‘ ×××•×“"])
    answers["safety"] = st.radio("×¢×“ ×›××” ×—×©×•×‘×” ×¨××ª ×‘×˜×™×—×•×ª?", ["× ××•×š", "×‘×™× ×•× ×™", "×’×‘×•×” ×××•×“"])
    answers["extra"] = st.text_area("×™×© ××©×”×• × ×•×¡×£ ×©×—×©×•×‘ ×œ×¦×™×™×Ÿ?")

    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    with st.spinner("ğŸ¤– GPT ×‘×•×—×¨ ×“×’××™× ×¨××©×•× ×™×™×..."):
        initial_models = analyze_needs_with_gpt(answers)
    st.info(f"ğŸ“‹ ×“×’××™× ×¨××©×•× ×™×™×: {initial_models}")

    min_budget = answers["budget_min"]
    max_budget = answers["budget_max"]
    engine = answers["engine"]

    with st.spinner("ğŸ‡®ğŸ‡± ××¡× ×Ÿ ×“×’××™× ××•×œ ××—×™×¨×•×Ÿ ×××™×ª×™ ×•×¡×•×’ ×× ×•×¢..."):
        israeli_models, debug_info = filter_models_for_israel(initial_models, min_budget, max_budget, engine)

    with st.expander("ğŸ” ×ª×©×•×‘×•×ª Perplexity ×œ×¡×™× ×•×Ÿ"):
        st.write(debug_info)

    if not israeli_models:
        st.error("âŒ ×œ× × ××¦××• ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ ×‘×”×ª×× ×œ×ª×§×¦×™×‘ ×•×œ×¡×•×’ ×”×× ×•×¢ ×©×‘×—×¨×ª.")
    else:
        st.success(f"âœ… ×“×’××™× ×–××™× ×™× ×‘×™×©×¨××œ: {israeli_models}")

        with st.spinner("ğŸŒ ×©×•×œ×£ × ×ª×•× ×™× ××œ××™× ×Ö¾Perplexity..."):
            models_data = fetch_models_data_with_perplexity(israeli_models, answers)

        with st.expander("ğŸ“Š × ×ª×•× ×™ Perplexity ×’×•×œ××™×™×"):
            st.write(models_data)

        with st.spinner("âš¡ ×™×•×¦×¨ ×”××œ×¦×” ×¡×•×¤×™×ª ×¢× GPT..."):
            summary = final_recommendation_with_gpt(answers, israeli_models, models_data)

        st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
        st.write(summary)
