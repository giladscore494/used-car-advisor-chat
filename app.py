import os
import re
import json
import requests
import datetime
import streamlit as st
import pandas as pd
from openai import OpenAI
import io

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not OPENAI_API_KEY or not PERPLEXITY_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Perplexity
# =============================
def safe_perplexity_call(prompt, model="llama-3.1-sonar-large-128k-online"):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {PERPLEXITY_API_KEY}"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3
    }
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=120)
        data = r.json()
        if "choices" not in data:
            return ""
        return data["choices"][0]["message"]["content"]
    except Exception:
        return ""

# =============================
# ×¤×™×¢× ×•×— ×˜×‘×œ×” ×-Perplexity
# =============================
def parse_perplexity_table(answer):
    try:
        dfs = pd.read_html(io.StringIO(answer))
        return dfs[0]  # ×œ×•×§×— ××ª ×”×˜×‘×œ×” ×”×¨××©×•× ×”
    except Exception:
        return pd.DataFrame()

# =============================
# ×¤×•× ×§×¦×™×™×ª × ×¨××•×œ
# =============================
def normalize_text(val):
    if not isinstance(val, str):
        return ""
    return val.strip().replace("-", "").replace("Ö¾", "").replace(" ", "").lower()

# =============================
# ×©×œ×‘ 1 â€“ ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ××•×œ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”
# =============================
def filter_with_mot(answers, mot_file="car_models_israel_clean.csv"):
    if not os.path.exists(mot_file):
        st.error(f"âŒ ×§×•×‘×¥ ×”×××’×¨ '{mot_file}' ×œ× × ××¦× ×‘×ª×™×§×™×™×”. ×•×“× ×©×”×¢×œ×™×ª ××•×ª×•.")
        return []

    df = pd.read_csv(mot_file, encoding="utf-8-sig", on_bad_lines="skip")

    for col in ["year", "engine_cc"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # × ×¨××•×œ
    df["fuel_norm"] = df["fuel"].apply(normalize_text)
    engine_norm = normalize_text(answers["engine"])

    df["gearbox_norm"] = df["automatic"].apply(lambda x: "××•×˜×•××˜" if x == 1 else "×™×“× ×™")

    # ×¡×™× ×•×Ÿ
    year_min = int(answers["year_min"])
    year_max = int(answers["year_max"])
    cc_min = int(answers["engine_cc_min"])
    cc_max = int(answers["engine_cc_max"])

    mask_year = df["year"].between(year_min, year_max, inclusive="both")
    mask_cc = df["engine_cc"].between(cc_min, cc_max, inclusive="both")
    mask_fuel = (answers["engine"] == "×œ× ××©× ×”") | (df["fuel_norm"] == engine_norm)
    mask_gear = (answers["gearbox"] == "×œ× ××©× ×”") | (df["gearbox_norm"] == answers["gearbox"])

    df_filtered = df[mask_year & mask_cc & mask_fuel & mask_gear].copy()

    return df_filtered.to_dict(orient="records")

# =============================
# ×©×œ×‘ 2 â€“ Perplexity ××—×–×™×¨ ×˜×‘×œ×”
# =============================
def fetch_models_table(answers, verified_models):
    if not verified_models:
        models_text = "[]"
    else:
        models_text = json.dumps(verified_models[:10], ensure_ascii=False)

    prompt = f"""
×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª ×”×‘××•×ª:
{answers}

×¨×©×™××ª ×“×’××™× ××¡×•× × ×™× (×¢×“ 10 ×©×•×¨×•×ª):
{models_text}

×”×—×–×¨ ××š ×•×¨×§ ×˜×‘×œ×” ×‘×¤×•×¨××˜ Markdown ×¢× ×¢××•×“×•×ª:
×“×’× | ×˜×•×•×— ××—×™×¨×•×Ÿ (â‚ª) | ×–××™× ×•×ª ×‘×™×©×¨××œ | ×‘×™×˜×•×— (â‚ª) | ××’×¨×ª ×¨×™×©×•×™ (â‚ª) | ×ª×—×–×•×§×” (â‚ª) | ×ª×§×œ×•×ª × ×¤×•×¦×•×ª | ×¦×¨×™×›×ª ×“×œ×§ (×§×´×/×œ×³) | ×™×¨×™×“×ª ×¢×¨×š (%) | ×‘×˜×™×—×•×ª | ×—×œ×¤×™× ×‘×™×©×¨××œ | ×˜×•×¨×‘×• | ××—×•×¥ ×œ×ª×§×¦×™×‘
"""
    answer = safe_perplexity_call(prompt)
    return parse_perplexity_table(answer)

# =============================
# ×©×œ×‘ 3 â€“ GPT ××¡×›× ×•××“×¨×’
# =============================
def final_recommendation_with_gpt(answers, df_params):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    ×˜×‘×œ×ª ×¤×¨××˜×¨×™×:
    {df_params.to_dict(orient="records")}

    ×¦×•×¨ ×¡×™×›×•× ×‘×¢×‘×¨×™×ª:
    - ×‘×—×¨ ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ××œ ×ª×›×œ×•×œ ×“×’××™× ×¢× '××—×•×¥ ×œ×ª×§×¦×™×‘' = true
    - ×¤×¨×˜ ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - ×”×ª×™×™×—×¡ ×œ×¢×œ×•×ª ×‘×™×˜×•×—, ×ª×—×–×•×§×”, ×™×¨×™×“×ª ×¢×¨×š, ×××™× ×•×ª ×•×©×™××•×© ×¢×™×§×¨×™
    - ×”×¦×’ ××ª ×”× ×™×ª×•×— ××—×¨×™ ×”×˜×‘×œ×”
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.4,
    )
    return response.choices[0].message.content

# =============================
# ×¤×•× ×§×¦×™×™×ª ×œ×•×’
# =============================
def save_log(answers, df_params, summary, filename="car_advisor_logs.csv"):
    record = {
        "timestamp": datetime.datetime.now().isoformat(),
        "answers": json.dumps(answers, ensure_ascii=False),
        "params_data": df_params.to_json(orient="records", force_ascii=False),
        "summary": summary,
    }
    if os.path.exists(filename):
        existing = pd.read_csv(filename)
        new_df = pd.DataFrame([record])
        final = pd.concat([existing, new_df], ignore_index=True)
    else:
        final = pd.DataFrame([record])
    final.to_csv(filename, index=False, encoding="utf-8-sig")

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

with st.form("car_form"):
    answers = {}
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "5000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "20000"))

    answers["engine"] = st.radio("×× ×•×¢ ××•×¢×“×£:", ["×œ× ××©× ×”", "×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™-×‘× ×–×™×Ÿ", "×”×™×‘×¨×™×“×™-×“×™×–×œ", "×—×©××œ"])
    answers["engine_cc_min"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××™× ×™××œ×™ (×¡××´×§):", "1200"))
    answers["engine_cc_max"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××§×¡×™××œ×™ (×¡××´×§):", "2000"))
    answers["year_min"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××™× ×™××œ×™×ª:", "2000")
    answers["year_max"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××§×¡×™××œ×™×ª:", "2020")

    answers["car_type"] = st.selectbox("×¡×•×’ ×¨×›×‘:", ["×¡×“××Ÿ", "×”××¦'×‘×§", "SUV", "××™× ×™", "×¡×˜×™×™×©×Ÿ", "×˜× ×“×¨", "××©×¤×—×ª×™"])
    answers["gearbox"] = st.radio("×’×™×¨:", ["×œ× ××©× ×”", "××•×˜×•××˜", "×™×“× ×™"])
    answers["turbo"] = st.radio("×× ×•×¢ ×˜×•×¨×‘×•:", ["×œ× ××©× ×”", "×›×Ÿ", "×œ×"])
    answers["usage"] = st.radio("×©×™××•×© ×¢×™×§×¨×™:", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])
    answers["driver_age"] = st.selectbox("×’×™×œ ×”× ×”×’ ×”×¨××©×™:", ["×¢×“ 21", "21â€“24", "25â€“34", "35+"])
    answers["license_years"] = st.selectbox("×•×ª×§ ×¨×™×©×™×•×Ÿ × ×”×™×’×”:", ["×¤×—×•×ª ××©× ×”", "1â€“3 ×©× ×™×", "3â€“5 ×©× ×™×", "××¢×œ 5 ×©× ×™×"])
    answers["insurance_history"] = st.selectbox("×¢×‘×¨ ×‘×™×˜×•×—×™/×ª×¢×‘×•×¨×ª×™:", ["×œ×œ×", "×ª××•× ×” ××—×ª", "××¡×¤×¨ ×ª×‘×™×¢×•×ª"])
    answers["annual_km"] = st.selectbox("× ×¡×•×¢×” ×©× ×ª×™×ª (×§×´×):", ["×¢×“ 10,000", "10,000â€“20,000", "20,000â€“30,000", "××¢×œ 30,000"])
    answers["passengers"] = st.selectbox("××¡×¤×¨ × ×•×¡×¢×™× ×¢×™×§×¨×™:", ["×œ×¨×•×‘ ×œ×‘×“", "2 ×× ×©×™×", "3â€“5 × ×•×¡×¢×™×", "××¢×œ 5"])
    answers["maintenance_budget"] = st.selectbox("×™×›×•×œ×ª ×ª×—×–×•×§×”:", ["××ª×—×ª 3,000 â‚ª", "3,000â€“5,000 â‚ª", "××¢×œ 5,000 â‚ª"])
    answers["reliability_vs_comfort"] = st.selectbox("××” ×—×©×•×‘ ×™×•×ª×¨?", ["×××™× ×•×ª ××¢×œ ×”×›×•×œ", "××™×–×•×Ÿ ×××™× ×•×ª ×•× ×•×—×•×ª", "× ×•×—×•×ª/×‘×™×¦×•×¢×™×"])
    answers["eco_pref"] = st.selectbox("×©×™×§×•×œ×™ ××™×›×•×ª ×¡×‘×™×‘×”:", ["×—×©×•×‘ ×¨×›×‘ ×™×¨×•×§/×—×¡×›×•× ×™", "×œ× ××©× ×”"])
    answers["resale_value"] = st.selectbox("×©××™×¨×ª ×¢×¨×š ×¢×ª×™×“×™×ª:", ["×—×©×•×‘ ×œ×©××•×¨ ×¢×œ ×¢×¨×š", "×¤×—×•×ª ×—×©×•×‘"])
    answers["extra"] = st.text_area("××©×”×• × ×•×¡×£ ×©×ª×¨×¦×” ×œ×¦×™×™×Ÿ?")

    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

# =============================
# ×˜×™×¤×•×œ ××—×¨×™ ×©×œ×™×—×”
# =============================
if submitted:
    with st.spinner("ğŸ“Š ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ××•×œ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”..."):
        verified_models = filter_with_mot(answers)

    with st.spinner("ğŸŒ Perplexity ×‘×•× ×” ×˜×‘×œ×ª ×¤×¨××˜×¨×™×..."):
        df_params = fetch_models_table(answers, verified_models)

    if not df_params.empty:
        st.subheader("ğŸŸ© ×˜×‘×œ×ª ×¤×¨××˜×¨×™×")
        st.dataframe(df_params, use_container_width=True)

        with st.spinner("âš¡ GPT ××¡×›× ×•××“×¨×’..."):
            summary = final_recommendation_with_gpt(answers, df_params)
            st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
            st.write(summary)

        save_log(answers, df_params, summary)
    else:
        st.warning("âš ï¸ ×œ× ×”×ª×§×‘×œ×” ×˜×‘×œ×ª ×¤×¨××˜×¨×™× ×ª×§×™× ×” ×-Perplexity")
