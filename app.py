import os
import re
import json
import requests
import datetime
import streamlit as st
import pandas as pd
from openai import OpenAI

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not OPENAI_API_KEY or not PERPLEXITY_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Perplexity
# =============================
def safe_perplexity_call(prompt, model="llama-3.1-sonar-large-128k-online"):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {PERPLEXITY_API_KEY}"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3
    }
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=120)
        data = r.json()
        if "choices" not in data:
            return f"×©×’×™××ª Perplexity: {data}"
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

# =============================
# ×©×œ×‘ 1 â€“ ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ××•×œ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”
# =============================
def filter_with_mot(answers, mot_file="car_models_israel_clean.csv"):
    if not os.path.exists(mot_file):
        st.error(f"âŒ ×§×•×‘×¥ ×”×××’×¨ '{mot_file}' ×œ× × ××¦× ×‘×ª×™×§×™×™×”. ×•×“× ×©×”×¢×œ×™×ª ××•×ª×•.")
        return []

    df = pd.read_csv(mot_file, encoding="utf-8-sig", on_bad_lines="skip")
    for col in ["year", "engine_cc"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    df["gearbox_norm"] = df["automatic"].apply(lambda x: "××•×˜×•××˜" if x == 1 else "×™×“× ×™")

    year_min = int(answers["year_min"])
    year_max = int(answers["year_max"])
    cc_min = int(answers["engine_cc_min"])
    cc_max = int(answers["engine_cc_max"])

    mask_year = df["year"].between(year_min, year_max, inclusive="both")
    mask_cc = df["engine_cc"].between(cc_min, cc_max, inclusive="both")
    mask_fuel = (answers["engine"] == "×œ× ××©× ×”") | (df["fuel"] == answers["engine"])
    mask_gear = (answers["gearbox"] == "×œ× ××©× ×”") | (df["gearbox_norm"] == answers["gearbox"])

    df_filtered = df[mask_year & mask_cc & mask_fuel & mask_gear].copy()
    return df_filtered.to_dict(orient="records")

# =============================
# ×©×œ×‘ 2 â€“ Perplexity ×‘×•× ×” ×˜×‘×œ×ª ×¤×¨××˜×¨×™×
# =============================
def fetch_models_10params(answers, verified_models):
    if not verified_models:
        return pd.DataFrame()

    models_text = pd.DataFrame(verified_models[:10]).to_markdown(index=False)

    prompt = f"""
×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª ×”×‘××•×ª:
{answers}

×¨×©×™××ª ×“×’××™× ××¡×•× × ×™× (×¢×“ 10 ×©×•×¨×•×ª ×œ×“×•×’××”):
{models_text}

×”×—×–×¨ ×˜×‘×œ×” ×‘×¤×•×¨××˜ Markdown ×¢× ×”×›×•×ª×¨×•×ª ×”×‘××•×ª:
| ×“×’× | ×˜×•×•×— ××—×™×¨×•×Ÿ | ×–××™× ×•×ª ×‘×™×©×¨××œ | ×‘×™×˜×•×— ×—×•×‘×” + ×¦×“ ×’×³ | ××’×¨×ª ×¨×™×©×•×™ | ×ª×—×–×•×§×” ×©× ×ª×™×ª | ×ª×§×œ×•×ª × ×¤×•×¦×•×ª | ×¦×¨×™×›×ª ×“×œ×§ | ×™×¨×™×“×ª ×¢×¨×š | ×‘×˜×™×—×•×ª | ×—×œ×¤×™× ×‘×™×©×¨××œ | ×˜×•×¨×‘×• | ××—×•×¥ ×œ×ª×§×¦×™×‘ |

×—×•×§×™×:
- ×¢×‘×•×¨ ×¢×œ ×›×œ ×”×“×’××™× ×©×¡×•×¤×§×• ×‘×¨×©×™××”.
- ××œ ×ª×—×–×™×¨ ×˜×§×¡×˜ ×—×•×¤×©×™ ××• ×”×¡×‘×¨×™× â€“ ××š ×•×¨×§ ×˜×‘×œ×” Markdown.
- ×× ×˜×•×•×— ×”××—×™×¨ ××—×•×¥ ×œ×ª×§×¦×™×‘ ({answers['budget_min']}â€“{answers['budget_max']} â‚ª) â†’ ×‘×¢××•×“×ª "××—×•×¥ ×œ×ª×§×¦×™×‘" ×¨×©×•× ×›×Ÿ, ××—×¨×ª ×œ×.
- ×× ×œ× ×™×“×•×¢ ×¢×¨×š ××¡×•×™× ×›×ª×•×‘ "×œ× ×™×“×•×¢".
"""

    answer = safe_perplexity_call(prompt)

    try:
        tables = pd.read_html(answer)
        if tables:
            return tables[0]
    except Exception:
        return pd.DataFrame()

    return pd.DataFrame()

# =============================
# ×©×œ×‘ 3 â€“ GPT ××¡×›× ×•××“×¨×’
# =============================
def final_recommendation_with_gpt(answers, df_params):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    ×˜×‘×œ×ª ×¤×¨××˜×¨×™×:
    {df_params.to_markdown(index=False)}

    ×¦×•×¨ ×¡×™×›×•× ×‘×¢×‘×¨×™×ª:
    - ×‘×—×¨ ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ××œ ×ª×›×œ×•×œ ×“×’××™× ×¢× "××—×•×¥ ×œ×ª×§×¦×™×‘" = ×›×Ÿ
    - ×¤×¨×˜ ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - ×”×ª×™×™×—×¡ ×œ×¢×œ×•×ª ×‘×™×˜×•×—, ×ª×—×–×•×§×”, ×™×¨×™×“×ª ×¢×¨×š, ×××™× ×•×ª ×•×©×™××•×© ×¢×™×§×¨×™
    - ×”×¦×’ ×˜×‘×œ×” ××¡×›××ª ×¢× 10 ×¤×¨××˜×¨×™×
    - ×”×¡×‘×¨ ×œ××” ×”×“×’××™× ×”×›×™ ××ª××™××™×
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.4,
    )
    return response.choices[0].message.content

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

with st.form("car_form"):
    answers = {}
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "5000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "20000"))

    answers["engine"] = st.radio("×× ×•×¢ ××•×¢×“×£:", ["×œ× ××©× ×”", "×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™-×‘× ×–×™×Ÿ", "×”×™×‘×¨×™×“×™-×“×™×–×œ", "×—×©××œ"])
    answers["engine_cc_min"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××™× ×™××œ×™ (×¡××´×§):", "1200"))
    answers["engine_cc_max"] = int(st.text_input("× ×¤×— ×× ×•×¢ ××§×¡×™××œ×™ (×¡××´×§):", "2000"))
    answers["year_min"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××™× ×™××œ×™×ª:", "2000")
    answers["year_max"] = st.text_input("×©× ×ª ×™×™×¦×•×¨ ××§×¡×™××œ×™×ª:", "2020")

    answers["car_type"] = st.selectbox("×¡×•×’ ×¨×›×‘:", ["×¡×“××Ÿ", "×”××¦'×‘×§", "SUV", "××™× ×™", "×¡×˜×™×™×©×Ÿ", "×˜× ×“×¨", "××©×¤×—×ª×™"])
    answers["gearbox"] = st.radio("×’×™×¨:", ["×œ× ××©× ×”", "××•×˜×•××˜", "×™×“× ×™"])
    answers["turbo"] = st.radio("×× ×•×¢ ×˜×•×¨×‘×•:", ["×œ× ××©× ×”", "×›×Ÿ", "×œ×"])
    answers["usage"] = st.radio("×©×™××•×© ×¢×™×§×¨×™:", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])

    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    with st.spinner("ğŸ“Š ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ××•×œ ×××’×¨ ××©×¨×“ ×”×ª×—×‘×•×¨×”..."):
        verified_models = filter_with_mot(answers)

    with st.spinner("ğŸŒ Perplexity ×‘×•× ×” ×˜×‘×œ×ª ×¤×¨××˜×¨×™×..."):
        df_params = fetch_models_10params(answers, verified_models)

    if not df_params.empty:
        with st.spinner("âš¡ GPT ××¡×›× ×•××“×¨×’..."):
            summary = final_recommendation_with_gpt(answers, df_params)

        st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
        st.write(summary)
    else:
        st.warning("âš ï¸ ×œ× ×”×ª×§×‘×œ×” ×˜×‘×œ×ª ×¤×¨××˜×¨×™× ×ª×§×™× ×” ×-Perplexity")
