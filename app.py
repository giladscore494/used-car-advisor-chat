# -*- coding: utf-8 -*-
# UsedCarAdvisor â€“ Free-text enabled chatbot
# Run: streamlit run app.py

import os
import json
import re
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

try:
    import google.generativeai as genai
except Exception:
    genai = None

st.set_page_config(page_title="×™×•×¢×¥ ×¨×›×‘×™× ×™×“ 2 â€“ ×¦'××˜ ×—×›×", page_icon="ğŸ¤–ğŸš—", layout="centered")

RTL = """
<style>
html, body, [class*="css"] { direction: rtl; text-align: right; }
.block-container { padding-top: .6rem; max-width: 880px; }
.stChatMessage { text-align: right; }
</style>
"""
st.markdown(RTL, unsafe_allow_html=True)

# =========================
# ×›×¤×ª×•×¨ ×”×ª×—×œ ××—×“×©
# =========================
if st.sidebar.button("ğŸ”„ ×”×ª×—×œ ××—×“×©"):
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.rerun()

# =========================
# Provider setup
# =========================
PROVIDER = st.sidebar.selectbox("×¡×¤×§ ××•×“×œ", ["OpenAI", "Gemini"], index=0)
openai_key = os.getenv("OPENAI_API_KEY", "")
gemini_key = os.getenv("GEMINI_API_KEY", "") or os.getenv("GOOGLE_API_KEY", "")

if PROVIDER == "OpenAI":
    has_key = bool(openai_key and OpenAI)
    model_name = st.sidebar.text_input("OpenAI Model", value="gpt-4.1-mini")
    oai_client = OpenAI(api_key=openai_key) if has_key else None
else:
    has_key = bool(gemini_key and genai)
    model_name = st.sidebar.text_input("Gemini Model", value="gemini-1.5-flash")
    if has_key:
        genai.configure(api_key=gemini_key)
        gem_model = genai.GenerativeModel(model_name)
    else:
        gem_model = None

st.sidebar.markdown(f"**×¡×˜×˜×•×¡ ×¡×¤×§:** {'âœ… ××—×•×‘×¨' if has_key else 'âŒ ×œ×œ× ××¤×ª×—/×¡×¤×¨×™×”'}")

# =========================
# App state
# =========================
if "messages" not in st.session_state:
    st.session_state.messages: List[Dict[str, str]] = [
        {"role":"assistant","content":"×”×™×™! ×¡×¤×¨ ×œ×™ ×‘××™×œ×™× ×©×œ×š ××™×–×” ×¨×›×‘ ××ª×” ××—×¤×© â€“ ××¤×©×¨ ×—×•×¤×©×™ (×œ×“×•×’××”: '×‘× ×œ×™ ×—×™×™×ª ×›×‘×™×© ××™×˜×œ×§×™×ª ×¢×“ 80 ××œ×£')."}
    ]
if "answers" not in st.session_state:
    st.session_state.answers: Dict[str, Any] = {}

# =========================
# Helpers
# =========================
def call_model(prompt: str) -> str:
    try:
        if PROVIDER == "OpenAI" and has_key and oai_client:
            resp = oai_client.chat.completions.create(
                model=model_name,
                messages=[{"role":"user","content":prompt}],
                temperature=0.2,
            )
            return resp.choices[0].message.content
        elif PROVIDER == "Gemini" and has_key and gem_model:
            r = gem_model.generate_content(prompt)
            return r.text or ""
    except Exception as e:
        return f"(×©×’×™××” ×‘×§×¨×™××” ×œ××•×“×œ: {e})"
    return "(××™×Ÿ ×—×™×‘×•×¨ ×œ××•×“×œ)"

def interpret_free_text(user_text: str) -> Dict[str, Any]:
    prompt = f"""
    ×”××©×ª××© ×›×ª×‘: "{user_text}"
    ×¢×œ×™×š ×œ× ×ª×— ×–××ª ×œ×“×¨×™×©×•×ª ×¨×›×‘.
    ×”×©×“×•×ª ×”××¤×©×¨×™×™×:
    - budget_min, budget_max (××¡×¤×¨×™× ×‘×©×§×œ×™× ×× ×¦×•×™×Ÿ)
    - body (××©×¤×—×ª×™, ×”××¦'×‘×§, ×’'×™×¤, ×¡×“××Ÿ, ×§×•×¤×”...)
    - character (×¡×¤×•×¨×˜×™×‘×™, ×™×•××™×•××™)
    - fuel (×‘× ×–×™×Ÿ, ×“×™×–×œ, ×”×™×‘×¨×™×“×™, ×—×©××œ×™)
    - turbo (×¢× ×˜×•×¨×‘×• / ×‘×œ×™ ×˜×•×¨×‘×• ×× ×”×•×–×›×¨)
    - brand (××•×ª×’ ×× ×¦×•×™×Ÿ, ××—×¨×ª null)
    - engine_size (× ×¤×— ×× ×•×¢ ×× ×¦×•×™×Ÿ, ××—×¨×ª null)

    ×”×—×–×¨ JSON ×‘×œ×‘×“. ×œ××©×œ:
    {{
      "budget_min": 40000,
      "budget_max": 80000,
      "body": "×”××¦'×‘×§",
      "character": "×¡×¤×•×¨×˜×™×‘×™",
      "fuel": "×‘× ×–×™×Ÿ",
      "turbo": "×¢× ×˜×•×¨×‘×•",
      "brand": "××œ×¤× ×¨×•××™××•",
      "engine_size": 1700
    }}
    """
    txt = call_model(prompt)
    try:
        data = json.loads(re.search(r"\{.*\}", txt, re.S).group())
        return data
    except Exception:
        return {}

def progress_bar(answers: Dict[str,Any]):
    required = ["budget_min","budget_max","body","character","fuel","year_min","engine_size","turbo"]
    filled = sum(1 for k in required if k in answers and answers[k] not in [None,"",0])
    pct = int(100 * filled / len(required))
    st.markdown(f"**×”×ª×§×“××•×ª ×”×©××œ×•×Ÿ:** {pct}%")
    st.progress(pct)

# =========================
# Display history
# =========================
st.markdown("## ğŸ¤– ×™×•×¢×¥ ×¨×›×‘×™× â€“ ×¦'××˜ ×—×›×")
progress_bar(st.session_state.answers)

for m in st.session_state.messages:
    with st.chat_message("assistant" if m["role"]=="assistant" else "user"):
        st.markdown(m["content"])

# =========================
# Chat input
# =========================
user_text = st.chat_input("×›×ª×•×‘ ×‘×—×•×¤×©×™×•×ª ××” ××ª×” ××—×¤×©...")

if user_text:
    st.session_state.messages.append({"role":"user","content":user_text})
    parsed = interpret_free_text(user_text)
    st.session_state.answers.update({k:v for k,v in parsed.items() if v not in [None,"",0]})

    # ×¡×™×›×•× ×“×¨×™×©×•×ª ×¢×“ ×›×”
    answers = st.session_state.answers
    summary_lines = []
    for k,v in answers.items():
        summary_lines.append(f"- {k}: {v}")
    summary_text = "### ×¡×™×›×•× ×“×¨×™×©×•×ª×™×š (×¢×“ ×›×”)\n" + "\n".join(summary_lines)
    with st.chat_message("assistant"):
        st.markdown(summary_text)
    st.session_state.messages.append({"role":"assistant","content":summary_text})

    # ×× ××•×œ××• × ×ª×•× ×™× ××¡×¤×™×§×™× â†’ ×—×™×¤×•×© ×“×’××™×
    if "budget_max" in answers and "body" in answers:
        with st.chat_message("assistant"):
            st.markdown("âœ… ××—×¤×© ×¨×›×‘×™× ××ª××™××™× ×‘×™×©×¨××œ...")

        prompt = f"""
        ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×§×¨×™×˜×¨×™×•× ×™×: {json.dumps(answers, ensure_ascii=False)},
        ×‘×—×¨ 5 ×“×’××™ ×¨×›×‘×™× ×™×“ ×©× ×™×™×” ×”× ××›×¨×™× ×‘×™×©×¨××œ ×‘×œ×‘×“.
        ×× ×”××©×ª××© ×‘×™×§×© ×˜×•×¨×‘×• â€“ ××œ ×ª×—×–×™×¨ ×“×’××™× ×‘×œ×™ ×˜×•×¨×‘×•.
        ×× ×”××©×ª××© ×¦×™×™×Ÿ ××•×ª×’ (brand) â€“ ×”×—×–×¨ ×¨×§ ×“×’××™× ×©×œ ××•×ª×’ ×–×”.
        ×”×—×–×¨ JSON:
        {{"recommendations":[{{"model":"×“×’×","why":"× ×™××•×§ ×§×¦×¨"}}]}}
        """
        txt = call_model(prompt)
        try:
            recs = json.loads(re.search(r"\{.*\}", txt, re.S).group())
        except Exception:
            recs = {"recommendations":[]}

        # ×˜×‘×œ×” ×¨××©×•× ×™×ª
        if recs.get("recommendations"):
            table_md = "| ×“×’× | × ×™××•×§ |\n|---|---|\n"
            for r in recs["recommendations"]:
                table_md += f"| {r['model']} | {r['why']} |\n"
            with st.chat_message("assistant"):
                st.markdown("### ×”×¦×¢×•×ª ×¨××©×•× ×™×•×ª\n" + table_md)
            st.session_state.messages.append({"role":"assistant","content":table_md})

st.markdown("---")
st.caption("×”××¤×œ×™×§×¦×™×” ××§×‘×œ×ª ×˜×§×¡×˜ ×—×•×¤×©×™ ××”××©×ª××©, ××¤×¢× ×—×ª ×œ×©×“×•×ª ××•×‘× ×™× (×›×•×œ×œ ××•×ª×’ ×× ×¦×•×™×Ÿ), ×•××—×–×™×¨×” ×”××œ×¦×•×ª ×¨×œ×•×•× ×˜×™×•×ª ×‘×œ×‘×“.")
