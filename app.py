import os
import re
import time
import json
import requests
import streamlit as st
import pandas as pd
from openai import OpenAI

# =============================
# ××¤×ª×—×•×ª API
# =============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not OPENAI_API_KEY or not PERPLEXITY_API_KEY:
    st.error("âŒ ×œ× × ××¦××• ××¤×ª×—×•×ª API. ×•×“× ×©×”×’×“×¨×ª ××•×ª× ×‘-secrets.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# Cache ×¤× ×™××™ (24 ×©×¢×•×ª)
# =============================
cache = {}

def make_key(answers):
    return f"{answers['budget_min']}-{answers['budget_max']}-{answers['engine']}-{answers['usage']}-{answers['size']}-{answers['car_type']}-{answers['turbo']}-{answers['gearbox']}-{answers['engine_size']}-{answers['year_range']}"

def get_from_cache(answers, max_age_hours=24):
    key = make_key(answers)
    if key in cache:
        ts, result = cache[key]
        if time.time() - ts < max_age_hours * 3600:
            return result
    return None

def save_to_cache(answers, result):
    key = make_key(answers)
    cache[key] = (time.time(), result)

# =============================
# ×§×¨×™××” ×‘×˜×•×—×” ×œ-Perplexity
# =============================
def safe_perplexity_call(payload):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {"Authorization": f"Bearer {PERPLEXITY_API_KEY}", "Content-Type": "application/json"}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=90)
        data = r.json()
        if "choices" not in data:
            return f"×©×’×™××ª API: {data}"
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"×©×’×™××”: {e}"

# =============================
# ×©×œ×‘ 1 â€“ GPT ××¦×™×¢ ×“×’××™× ×¨××©×•× ×™×™×
# =============================
def analyze_needs_with_gpt(answers):
    prompt = f"""
    ×”××©×ª××© × ×ª×Ÿ ××ª ×”×”×¢×“×¤×•×ª:
    {answers}

    ×”×—×–×¨ ×¨×©×™××” ×©×œ 7â€“10 ×“×’××™ ×¨×›×‘×™× ××¤×©×¨×™×™× (×©× ×‘×œ×‘×“).
    ××œ ×ª×•×¡×™×£ ××¤×¨×˜×™× (×©× ×”/××—×™×¨/×× ×•×¢).
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    text = response.choices[0].message.content
    models = []
    for line in text.split("\n"):
        line = line.strip()
        if not line or ":" in line:
            continue
        line = re.sub(r"^[0-9\.\-\â€¢\*\s]+", "", line)
        if line:
            models.append(line)
    return models

# =============================
# ×©×œ×‘ 2 â€“ ×¡×™× ×•×Ÿ ××•×§×“× ×‘-GPT (Pre-Filter)
# =============================
def prefilter_models_with_gpt(models, answers):
    prompt = f"""
    ×“×’××™× ××•×¦×¢×™×: {models}
    ×ª× ××™ ×¡×™× ×•×Ÿ: ×ª×§×¦×™×‘ {answers['budget_min']}â€“{answers['budget_max']} â‚ª,
    ×× ×•×¢ {answers['engine']} {answers['engine_size']} ×¡××´×§,
    ×©× ×•×ª ×™×™×¦×•×¨ {answers['year_range']},
    ×’×™×¨ {answers['gearbox']}, ×˜×•×¨×‘×• {answers['turbo']}.

    ×”×—×–×¨ ×¨×©×™××” ×§×¦×¨×” ×©×œ 3â€“4 ×“×’××™× ×¨×œ×•×•× ×˜×™×™× ×‘×œ×‘×“.
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    text = response.choices[0].message.content
    return [re.sub(r"^[0-9\.\-\â€¢\*\s]+", "", l.strip()) for l in text.split("\n") if l.strip()]

# =============================
# ×©×œ×‘ 3 â€“ ×‘×§×©×” ××—×ª ×œ×¤×¨×¤×œ×™×¡×™×˜×™ (Batch JSON)
# =============================
def fetch_models_data_with_perplexity(models, answers):
    models_str = ", ".join(models)
    payload = {
        "model": "sonar-pro",
        "messages": [
            {"role": "system", "content": "×¢× ×” ×‘×¤×•×¨××˜ JSON ×‘×œ×‘×“. ××œ ×ª×•×¡×™×£ ×˜×§×¡×˜ ×—×•×¤×©×™."},
            {"role": "user", "content": f"""
            ×”×‘× ××™×“×¢ ×¢×“×›× ×™ ×¢×œ ×”×“×’××™× ×”×‘××™× ×‘×™×©×¨××œ: {models_str}.

            ×¢×‘×•×¨ ×›×œ ×“×’× ×”×—×–×¨ ×‘×¤×•×¨××˜ JSON ×¢× ×”×©×“×•×ª:
            {{
              "Model Name": {{
                 "price_range": "×˜×•×•×— ××—×™×¨×•×Ÿ ×××•×¦×¢ ×‘×™×“ ×©× ×™×™×”",
                 "availability": "×–××™× ×•×ª ×‘×™×©×¨××œ",
                 "insurance": "×¢×œ×•×ª ×‘×™×˜×•×— ×××•×¦×¢×ª",
                 "license_fee": "××’×¨×ª ×¨×™×©×•×™/×˜×¡×˜ ×©× ×ª×™×ª",
                 "maintenance": "×ª×—×–×•×§×” ×©× ×ª×™×ª ×××•×¦×¢×ª",
                 "common_issues": "×ª×§×œ×•×ª × ×¤×•×¦×•×ª",
                 "fuel_consumption": "×¦×¨×™×›×ª ×“×œ×§ ×××™×ª×™×ª",
                 "depreciation": "×™×¨×™×“×ª ×¢×¨×š ×××•×¦×¢×ª",
                 "safety": "×“×™×¨×•×’ ×‘×˜×™×—×•×ª",
                 "parts_availability": "×–××™× ×•×ª ×—×œ×¤×™× ×‘×™×©×¨××œ"
              }}
            }}
            ××œ ×ª×•×¡×™×£ ×˜×§×¡×˜ ××¢×‘×¨ ×œ-JSON.
            """}
        ]
    }
    answer = safe_perplexity_call(payload)
    try:
        return json.loads(answer)
    except:
        return {"error": "JSON ×œ× ×ª×§×™×Ÿ", "raw": answer}

# =============================
# ×©×œ×‘ 4 â€“ GPT ××¡×›× ×”××œ×¦×”
# =============================
def final_recommendation_with_gpt(answers, models, models_data):
    text = f"""
    ×ª×©×•×‘×•×ª ×”××©×ª××©:
    {answers}

    ×“×’××™× ×–××™× ×™×:
    {models}

    × ×ª×•× ×™ Perplexity:
    {models_data}

    ×¦×•×¨ ×”××œ×¦×” ×‘×¢×‘×¨×™×ª:
    - ×¢×“ 5 ×“×’××™× ×‘×œ×‘×“
    - ×™×ª×¨×•× ×•×ª ×•×—×¡×¨×•× ×•×ª
    - × ×™××•×§×™× ××™×©×™×™× ×œ×¤×™ ×”×ª×§×¦×™×‘, ×¡×•×’ ×× ×•×¢, ×©× ×•×ª ×™×™×¦×•×¨, ×˜×•×¨×‘×• ×•×’×™×¨
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": text}],
        temperature=0.5,
    )
    return response.choices[0].message.content

# =============================
# UI
# =============================
st.set_page_config(page_title="Car-Advisor", page_icon="ğŸš—")
st.title("ğŸš— Car-Advisor â€“ ×™×•×¢×¥ ×¨×›×‘×™× ×—×›×")

COLUMN_TRANSLATIONS = {
    "price_range": "×˜×•×•×— ××—×™×¨×•×Ÿ",
    "availability": "×–××™× ×•×ª ×‘×™×©×¨××œ",
    "insurance": "×¢×œ×•×ª ×‘×™×˜×•×—",
    "license_fee": "××’×¨×ª ×¨×™×©×•×™",
    "maintenance": "×ª×—×–×•×§×” ×©× ×ª×™×ª",
    "common_issues": "×ª×§×œ×•×ª × ×¤×•×¦×•×ª",
    "fuel_consumption": "×¦×¨×™×›×ª ×“×œ×§",
    "depreciation": "×™×¨×™×“×ª ×¢×¨×š",
    "safety": "×‘×˜×™×—×•×ª",
    "parts_availability": "×—×œ×¤×™× ×‘×™×©×¨××œ"
}

with st.form("car_form"):
    answers = {}
    answers["budget_range"] = st.selectbox("×˜×•×•×— ×ª×§×¦×™×‘:", ["5â€“10K", "10â€“20K", "20â€“40K", "40K+"])
    answers["budget_min"] = int(st.text_input("×ª×§×¦×™×‘ ××™× ×™××œ×™ (â‚ª)", "10000"))
    answers["budget_max"] = int(st.text_input("×ª×§×¦×™×‘ ××§×¡×™××œ×™ (â‚ª)", "20000"))
    answers["engine"] = st.radio("×× ×•×¢ ××•×¢×“×£:", ["×‘× ×–×™×Ÿ", "×“×™×–×œ", "×”×™×‘×¨×™×“×™", "×—×©××œ×™"])
    answers["engine_size"] = st.selectbox("× ×¤×— ×× ×•×¢ (×¡××´×§):", ["1200", "1600", "2000", "3000+"])
    answers["year_range"] = st.selectbox("×©× ×•×ª ×™×™×¦×•×¨:", ["2010â€“2015", "2016â€“2020", "2021+"])
    answers["car_type"] = st.selectbox("×¡×•×’ ×¨×›×‘:", ["×¡×“××Ÿ", "×”××¦'×‘×§", "SUV", "×˜× ×“×¨", "××©×¤×—×ª×™"])
    answers["turbo"] = st.radio("×× ×•×¢ ×˜×•×¨×‘×•:", ["×œ× ××©× ×”", "×›×Ÿ", "×œ×"])
    answers["gearbox"] = st.radio("×’×™×¨:", ["×œ× ××©× ×”", "××•×˜×•××˜", "×™×“× ×™", "×¨×•×‘×•×˜×™"])
    answers["usage"] = st.radio("×©×™××•×© ×¢×™×§×¨×™:", ["×¢×™×¨×•× ×™", "×‘×™×Ÿ-×¢×™×¨×•× ×™", "××¢×•×¨×‘"])
    answers["size"] = st.selectbox("×’×•×“×œ ×¨×›×‘:", ["×§×˜×Ÿ", "××©×¤×—×ª×™", "SUV", "×˜× ×“×¨"])
    answers["extra"] = st.text_area("××©×”×• × ×•×¡×£?")

    submitted = st.form_submit_button("×©×œ×— ×•×§×‘×œ ×”××œ×¦×”")

if submitted:
    cached = get_from_cache(answers)
    if cached:
        st.success("âœ… ×ª×•×¦××” ××”×××’×¨")
        summary = cached
    else:
        with st.spinner("ğŸ¤– ××—×¤×© ×“×’××™× ××ª××™××™×..."):
            initial = analyze_needs_with_gpt(answers)
            st.info(f"ğŸ“‹ ×“×’××™× ×¨××©×•× ×™×™×: {initial}")

            filtered = prefilter_models_with_gpt(initial, answers)
            st.success(f"âœ… ×“×’××™× ×œ××—×¨ ×¡×™× ×•×Ÿ ××•×§×“×: {filtered}")

            data = fetch_models_data_with_perplexity(filtered, answers)

            try:
                df = pd.DataFrame(data).T
                df.rename(columns=COLUMN_TRANSLATIONS, inplace=True)
                st.subheader("ğŸ“Š ×”×©×•×•××ª × ×ª×•× ×™×")
                st.dataframe(df, use_container_width=True)
                # ×›×¤×ª×•×¨ ×”×•×¨×“×” ×œ-CSV
                csv = df.to_csv(index=True, encoding="utf-8-sig")
                st.download_button("â¬‡ï¸ ×”×•×¨×“ ×›-CSV", csv, "car_advisor.csv", "text/csv")
            except:
                st.warning("âš ï¸ ×‘×¢×™×” ×‘× ×ª×•× ×™ JSON")
                st.write(data)

            with st.spinner("âš¡ ××¡×›× ×”××œ×¦×”..."):
                summary = final_recommendation_with_gpt(answers, filtered, data)

            st.subheader("ğŸ” ×”×”××œ×¦×” ×”×¡×•×¤×™×ª ×©×œ×š")
            st.write(summary)

            save_to_cache(answers, summary)

    st.markdown("---")
    st.markdown("âš ï¸ **×—×©×•×‘ ×œ×“×¢×ª:**")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(
            f'<a href="https://infocar.co.il/" target="_blank">'
            f'<button style="background-color:#117A65;color:white;padding:10px 20px;'
            f'border:none;border-radius:8px;font-size:16px;cursor:pointer;">'
            f'ğŸ”— ×‘×“×•×§ ×¢×‘×¨ ×‘×™×˜×•×—×™ ×‘-InfoCar</button></a>',
            unsafe_allow_html=True
        )
    with col2:
        st.markdown("ğŸš— ×¨×¦×•×™ ×œ×§×—×ª ××ª ×”×¨×›×‘ ×œ×‘×“×™×§×” ×‘××›×•×Ÿ ×‘×“×™×§×” ××•×¨×©×” ×œ×¤× ×™ ×¨×›×™×©×”.")
